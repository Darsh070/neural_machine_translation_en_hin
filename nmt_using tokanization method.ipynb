{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural translation machine from hindi-english language open source corpouas from statsloc.pou\n",
    "https://www.kaggle.com/aiswaryaramachandran/english-to-hindi-neural-machine-translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darshit\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:27: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=pd.read_csv(\"E:/kaggle_dataset/hindi_english_parallel/hindi_english_parallel.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "      <td>Give your application an accessibility workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
       "      <td>Accerciser Accessibility Explorer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the bottom panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the top panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
       "      <td>A list of plugins that are disabled by default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>अवधि को हाइलाइट रकें</td>\n",
       "      <td>Highlight duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्स...</td>\n",
       "      <td>The duration of the highlight box when selecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>सीमांत (बोर्डर) के रंग को हाइलाइट करें</td>\n",
       "      <td>Highlight border color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता।</td>\n",
       "      <td>The color and opacity of the highlight border.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>भराई के रंग को हाइलाइट करें</td>\n",
       "      <td>Highlight fill color</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               hindi  \\\n",
       "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
       "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n",
       "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n",
       "5                               अवधि को हाइलाइट रकें   \n",
       "6  पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्स...   \n",
       "7             सीमांत (बोर्डर) के रंग को हाइलाइट करें   \n",
       "8      हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता।    \n",
       "9                        भराई के रंग को हाइलाइट करें   \n",
       "\n",
       "                                             english  \n",
       "0     Give your application an accessibility workout  \n",
       "1                  Accerciser Accessibility Explorer  \n",
       "2     The default plugin layout for the bottom panel  \n",
       "3        The default plugin layout for the top panel  \n",
       "4     A list of plugins that are disabled by default  \n",
       "5                                 Highlight duration  \n",
       "6  The duration of the highlight box when selecti...  \n",
       "7                             Highlight border color  \n",
       "8     The color and opacity of the highlight border.  \n",
       "9                               Highlight fill color  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[~pd.isnull(lines['english'])]\n",
    "lines=lines[~pd.isnull(lines['hindi'])]\n",
    "lines.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines=lines.sample(n=250,random_state=42)# sample n=2500\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines['english']=lines['english'].apply(lambda x: x.lower())\n",
    "lines['hindi']=lines['hindi'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Remove quotes\n",
    "lines['english']=lines['english'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi']=lines['hindi'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines['english']=lines['english'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi']=lines['hindi'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english']=lines['english'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi']=lines['hindi'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi'] = lines['hindi'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english']=lines['english'].apply(lambda x: x.strip())\n",
    "lines['hindi']=lines['hindi'].apply(lambda x: x.strip())\n",
    "lines['english']=lines['english'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi']=lines['hindi'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines['hindi'] = lines['hindi'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1089912</th>\n",
       "      <td>START_ लेकिन इन तीरों आकर्षित करने के लिए सबसे आसान तरीका है मैं हमेशा करता है और _END</td>\n",
       "      <td>but the easiest way i always do is to draw these arrows and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307295</th>\n",
       "      <td>START_ कह दो इसे ता पवित्र आत्मा ने तुम्हारे रब की ओर क्रमशः सत्य के साथ उतारा है ताकि ईमान लानेवालों को जमाव प्रदान करे और आज्ञाकारियों के लिए मार्गदर्शन और शुभ सूचना हो _END</td>\n",
       "      <td>say “the holy spirit has brought it down from your lord truthfully in order to stabilize those who believe and as guidance and good news for those who submit ”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654271</th>\n",
       "      <td>START_ जिसके पास कैंसर का इलाज है _END</td>\n",
       "      <td>who had the cure for cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221838</th>\n",
       "      <td>START_ ‘‘बहुत सारी मशीनरी और ऐसी ही वस्तुओं के प्रयोग से भौतिक जीवन के सुखों को बढ़ाने में सफलता प्राप्त करने से ही कोई राष्ट्र सभ्य नहीं बन सकता इस युग में जहां एक ओर लोगों को अत्यंत व्यावहारिक बना होगा वहीं दूसरी ओर उन्हें गहरा आध्यात्मिक ज्ञान प्राप्त करना होगा। ’’ _END</td>\n",
       "      <td>no nation can be said to have become civilized only because it has succeeded in increasing the comforts of material life by bringing into use lots of machinery and things of that sort in this age as on the one hand people have to be intensely practical so on the other they have to acquire deep spiritual knowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005692</th>\n",
       "      <td>START_ समुचित या पर्याप्त मात्रा में। _END</td>\n",
       "      <td>something that is adequate or sufficient in quantity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                     hindi                                                                                                                                                                                                                                                                                                                     english\n",
       "1089912  START_ लेकिन इन तीरों आकर्षित करने के लिए सबसे आसान तरीका है मैं हमेशा करता है और _END                                                                                                                                                                                             but the easiest way i always do is to draw these arrows and                                                                                                                                                                                                                                                               \n",
       "307295   START_ कह दो इसे ता पवित्र आत्मा ने तुम्हारे रब की ओर क्रमशः सत्य के साथ उतारा है ताकि ईमान लानेवालों को जमाव प्रदान करे और आज्ञाकारियों के लिए मार्गदर्शन और शुभ सूचना हो _END                                                                                                    say “the holy spirit has brought it down from your lord truthfully in order to stabilize those who believe and as guidance and good news for those who submit ”                                                                                                                                                           \n",
       "654271   START_ जिसके पास कैंसर का इलाज है _END                                                                                                                                                                                                                                             who had the cure for cancer                                                                                                                                                                                                                                                                                               \n",
       "1221838  START_ ‘‘बहुत सारी मशीनरी और ऐसी ही वस्तुओं के प्रयोग से भौतिक जीवन के सुखों को बढ़ाने में सफलता प्राप्त करने से ही कोई राष्ट्र सभ्य नहीं बन सकता इस युग में जहां एक ओर लोगों को अत्यंत व्यावहारिक बना होगा वहीं दूसरी ओर उन्हें गहरा आध्यात्मिक ज्ञान प्राप्त करना होगा। ’’ _END  no nation can be said to have become civilized only because it has succeeded in increasing the comforts of material life by bringing into use lots of machinery and things of that sort in this age as on the one hand people have to be intensely practical so on the other they have to acquire deep spiritual knowledge\n",
       "1005692  START_ समुचित या पर्याप्त मात्रा में। _END                                                                                                                                                                                                                                         something that is adequate or sufficient in quantity                                                                                                                                                                                                                                                                      "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in lines['english']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1337"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1526"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['length_eng_sentence']=lines['english'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1089912</th>\n",
       "      <td>START_ लेकिन इन तीरों आकर्षित करने के लिए सबसे आसान तरीका है मैं हमेशा करता है और _END</td>\n",
       "      <td>but the easiest way i always do is to draw these arrows and</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307295</th>\n",
       "      <td>START_ कह दो इसे ता पवित्र आत्मा ने तुम्हारे रब की ओर क्रमशः सत्य के साथ उतारा है ताकि ईमान लानेवालों को जमाव प्रदान करे और आज्ञाकारियों के लिए मार्गदर्शन और शुभ सूचना हो _END</td>\n",
       "      <td>say “the holy spirit has brought it down from your lord truthfully in order to stabilize those who believe and as guidance and good news for those who submit ”</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654271</th>\n",
       "      <td>START_ जिसके पास कैंसर का इलाज है _END</td>\n",
       "      <td>who had the cure for cancer</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221838</th>\n",
       "      <td>START_ ‘‘बहुत सारी मशीनरी और ऐसी ही वस्तुओं के प्रयोग से भौतिक जीवन के सुखों को बढ़ाने में सफलता प्राप्त करने से ही कोई राष्ट्र सभ्य नहीं बन सकता इस युग में जहां एक ओर लोगों को अत्यंत व्यावहारिक बना होगा वहीं दूसरी ओर उन्हें गहरा आध्यात्मिक ज्ञान प्राप्त करना होगा। ’’ _END</td>\n",
       "      <td>no nation can be said to have become civilized only because it has succeeded in increasing the comforts of material life by bringing into use lots of machinery and things of that sort in this age as on the one hand people have to be intensely practical so on the other they have to acquire deep spiritual knowledge</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005692</th>\n",
       "      <td>START_ समुचित या पर्याप्त मात्रा में। _END</td>\n",
       "      <td>something that is adequate or sufficient in quantity</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                     hindi                                                                                                                                                                                                                                                                                                                     english  length_eng_sentence  length_hin_sentence\n",
       "1089912  START_ लेकिन इन तीरों आकर्षित करने के लिए सबसे आसान तरीका है मैं हमेशा करता है और _END                                                                                                                                                                                             but the easiest way i always do is to draw these arrows and                                                                                                                                                                                                                                                                 13                   18                 \n",
       "307295   START_ कह दो इसे ता पवित्र आत्मा ने तुम्हारे रब की ओर क्रमशः सत्य के साथ उतारा है ताकि ईमान लानेवालों को जमाव प्रदान करे और आज्ञाकारियों के लिए मार्गदर्शन और शुभ सूचना हो _END                                                                                                    say “the holy spirit has brought it down from your lord truthfully in order to stabilize those who believe and as guidance and good news for those who submit ”                                                                                                                                                             30                   35                 \n",
       "654271   START_ जिसके पास कैंसर का इलाज है _END                                                                                                                                                                                                                                             who had the cure for cancer                                                                                                                                                                                                                                                                                                 6                    8                  \n",
       "1221838  START_ ‘‘बहुत सारी मशीनरी और ऐसी ही वस्तुओं के प्रयोग से भौतिक जीवन के सुखों को बढ़ाने में सफलता प्राप्त करने से ही कोई राष्ट्र सभ्य नहीं बन सकता इस युग में जहां एक ओर लोगों को अत्यंत व्यावहारिक बना होगा वहीं दूसरी ओर उन्हें गहरा आध्यात्मिक ज्ञान प्राप्त करना होगा। ’’ _END  no nation can be said to have become civilized only because it has succeeded in increasing the comforts of material life by bringing into use lots of machinery and things of that sort in this age as on the one hand people have to be intensely practical so on the other they have to acquire deep spiritual knowledge  58                   53                 \n",
       "1005692  START_ समुचित या पर्याप्त मात्रा में। _END                                                                                                                                                                                                                                         something that is adequate or sufficient in quantity                                                                                                                                                                                                                                                                        8                    7                  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines['length_eng_sentence']>30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  19\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1337, 1526)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 #for zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329620</th>\n",
       "      <td>START_ बेशक ये कुरान सरासर नसीहत है तो जो शख़्श चाहे अपने परवरदिगार की राह ले _END</td>\n",
       "      <td>verily this is an exhortation so let him who so will take a way to his lord</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335255</th>\n",
       "      <td>START_ एक स्थान पर वह अखंड कावेरी है सहायक नदियों के जल से उफनती विशाल नदी। _END</td>\n",
       "      <td>at one place it is akhanda kaveri the immense river swollen with tributaries</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998343</th>\n",
       "      <td>START_ कर लगे लाभ पर कर पुनः कर लगाना दोहरा कर लगाना होगा। _END</td>\n",
       "      <td>taxing taxed profits would amount to double taxation</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313866</th>\n",
       "      <td>START_ और यहूदी लोग कहते हैं कि खुदा ने अज़ीज़ को बेटा बना लिया है _END</td>\n",
       "      <td>and they say “the most merciful has begotten a son ”</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199393</th>\n",
       "      <td>START_ रेलवे सूचना प्रणाली केंद्र _END</td>\n",
       "      <td>centre for railway information systems</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203418</th>\n",
       "      <td>START_ भारत सरकार और भारतीय रिजर्व बैंक द्वारा समितियों के साथ सहयोग हाल के वर्ष _END</td>\n",
       "      <td>association with committees by goi and rbi recent years</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990168</th>\n",
       "      <td>START_ उपचार के बाद ही इस कि पुष्टि की गई कि वह बहुतंत्रिकार्ति से पीड़ित था _END</td>\n",
       "      <td>only after diagonisis it was confirmed that he was suffering from polyneuralgia</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222652</th>\n",
       "      <td>START_ केवर्ड एमिप्रो निर्यात फ़िल्टरname _END</td>\n",
       "      <td>kword amipro export filter</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964895</th>\n",
       "      <td>START_ वह नीचे अमेज़न नदी में छोटी नाव से यात्रा करने गया। _END</td>\n",
       "      <td>he went canoeing down the amazon river once</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506386</th>\n",
       "      <td>START_ परछाईयाँ उन्हे डरा देती थी एक ज़मीन पर पडा पाईप भी _END</td>\n",
       "      <td>shadows would make them balk a hose on the floor</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         hindi                                                                          english  length_eng_sentence  length_hin_sentence\n",
       "329620   START_ बेशक ये कुरान सरासर नसीहत है तो जो शख़्श चाहे अपने परवरदिगार की राह ले _END     verily this is an exhortation so let him who so will take a way to his lord      17                   17                 \n",
       "1335255  START_ एक स्थान पर वह अखंड कावेरी है सहायक नदियों के जल से उफनती विशाल नदी। _END       at one place it is akhanda kaveri the immense river swollen with tributaries     13                   17                 \n",
       "998343   START_ कर लगे लाभ पर कर पुनः कर लगाना दोहरा कर लगाना होगा। _END                        taxing taxed profits would amount to double taxation                             8                    14                 \n",
       "313866   START_ और यहूदी लोग कहते हैं कि खुदा ने अज़ीज़ को बेटा बना लिया है _END                and they say “the most merciful has begotten a son ”                             11                   16                 \n",
       "1199393  START_ रेलवे सूचना प्रणाली केंद्र _END                                                 centre for railway information systems                                           5                    6                  \n",
       "1203418  START_ भारत सरकार और भारतीय रिजर्व बैंक द्वारा समितियों के साथ सहयोग हाल के वर्ष _END  association with committees by goi and rbi recent years                          9                    16                 \n",
       "990168   START_ उपचार के बाद ही इस कि पुष्टि की गई कि वह बहुतंत्रिकार्ति से पीड़ित था _END      only after diagonisis it was confirmed that he was suffering from polyneuralgia  12                   17                 \n",
       "222652   START_ केवर्ड एमिप्रो निर्यात फ़िल्टरname _END                                         kword amipro export filter                                                       4                    6                  \n",
       "964895   START_ वह नीचे अमेज़न नदी में छोटी नाव से यात्रा करने गया। _END                        he went canoeing down the amazon river once                                      8                    13                 \n",
       "506386   START_ परछाईयाँ उन्हे डरा देती थी एक ज़मीन पर पडा पाईप भी _END                         shadows would make them balk a hose on the floor                                 10                   13                 "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((147,), (37,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spliting of data\n",
    "\n",
    "X, y = lines['english'], lines['hindi']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_trainenhi.pkl')\n",
    "X_test.to_pickle('X_testenhi.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder-Decoder Architecture\n",
    "latent_dim=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    401100      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    458100      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 1527)   459627      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,761,227\n",
      "Trainable params: 2,761,227\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)  #batch_size can give u the log error so accoring to ur data mention ur smaple in batch_size\n",
    "val_samples = len(X_test)\n",
    "batch_size = 10\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 17s 1s/step - loss: 2.5012 - val_loss: 2.6672\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 4s 266ms/step - loss: 2.3486 - val_loss: 2.7217\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 4s 263ms/step - loss: 2.1948 - val_loss: 2.8148\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 4s 261ms/step - loss: 2.1366 - val_loss: 2.9404\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 4s 260ms/step - loss: 2.0938 - val_loss: 3.0260\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 4s 261ms/step - loss: 2.0538 - val_loss: 3.0974\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 4s 264ms/step - loss: 1.9487 - val_loss: 3.1676\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 4s 260ms/step - loss: 1.9903 - val_loss: 3.2366\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 4s 262ms/step - loss: 1.8628 - val_loss: 3.3119\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 4s 272ms/step - loss: 1.8221 - val_loss: 3.2864\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 1.8351 - val_loss: 3.4150\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 4s 262ms/step - loss: 1.7636 - val_loss: 3.3771\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 4s 296ms/step - loss: 1.7249 - val_loss: 3.4399\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 4s 296ms/step - loss: 1.6468 - val_loss: 3.5303\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 4s 285ms/step - loss: 1.6464 - val_loss: 3.6363\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 1.5635 - val_loss: 3.6042\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 1.5365 - val_loss: 3.6934\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 1.4411 - val_loss: 3.7184\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 1.4417 - val_loss: 3.7268\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 1.4098 - val_loss: 3.7717\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 1.3898 - val_loss: 3.8102\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 1.3039 - val_loss: 3.7912\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 1.3355 - val_loss: 3.7138\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 1.2711 - val_loss: 3.6823\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 1.2572 - val_loss: 3.7987\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 1.2604 - val_loss: 3.8098\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 1.2080 - val_loss: 3.8567\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 1.1703 - val_loss: 3.8825\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 1.1223 - val_loss: 3.9203\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 1.0988 - val_loss: 3.9238\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 4s 264ms/step - loss: 1.0357 - val_loss: 3.9342\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 1.0299 - val_loss: 3.9395\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 0.9455 - val_loss: 3.9490\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 4s 260ms/step - loss: 0.9056 - val_loss: 3.9567\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.8575 - val_loss: 3.9740\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 0.8259 - val_loss: 3.9918\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.7743 - val_loss: 4.0074\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.7789 - val_loss: 4.0517\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 0.7051 - val_loss: 4.0710\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 0.6734 - val_loss: 4.0657\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 0.6349 - val_loss: 4.0862\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 0.6100 - val_loss: 4.0857\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 3s 250ms/step - loss: 0.5634 - val_loss: 4.0826\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.5085 - val_loss: 4.1122\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.4686 - val_loss: 4.1403\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 0.4281 - val_loss: 4.1541\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 0.4011 - val_loss: 4.1521\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 3s 250ms/step - loss: 0.3540 - val_loss: 4.1771\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 0.3228 - val_loss: 4.1945\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.2993 - val_loss: 4.2243\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.2738 - val_loss: 4.2471\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.2425 - val_loss: 4.2519\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 3s 249ms/step - loss: 0.2276 - val_loss: 4.2521\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.1991 - val_loss: 4.2540\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 3s 249ms/step - loss: 0.1827 - val_loss: 4.2457\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 0.1656 - val_loss: 4.2760\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.1465 - val_loss: 4.2984\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.1326 - val_loss: 4.2965\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 0.1115 - val_loss: 4.3333\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 0.1011 - val_loss: 4.3497\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 0.0886 - val_loss: 4.3537\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 0.0792 - val_loss: 4.3458\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 3s 249ms/step - loss: 0.0641 - val_loss: 4.3452\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.055 - 4s 252ms/step - loss: 0.0556 - val_loss: 4.3804\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0479 - val_loss: 4.3829\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0430 - val_loss: 4.4057\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 0.0350 - val_loss: 4.4150\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 0.0314 - val_loss: 4.4473\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0253 - val_loss: 4.4253\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0216 - val_loss: 4.4427\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0184 - val_loss: 4.4520\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 0.0158 - val_loss: 4.4747\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0121 - val_loss: 4.4708\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 0.0095 - val_loss: 4.5093\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0083 - val_loss: 4.5330\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0064 - val_loss: 4.5391\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0065 - val_loss: 4.5504\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 0.0049 - val_loss: 4.5563\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 0.0035 - val_loss: 4.5820\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0032 - val_loss: 4.5882\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 3s 250ms/step - loss: 0.0036 - val_loss: 4.6123\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 0.0026 - val_loss: 4.6124\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 3s 250ms/step - loss: 0.0017 - val_loss: 4.6487\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 0.0013 - val_loss: 4.6506\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 0.0011 - val_loss: 4.6746\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0012 - val_loss: 4.6276\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 3s 249ms/step - loss: 0.0023 - val_loss: 4.7411\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 0.0023 - val_loss: 4.7124\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 4s 268ms/step - loss: 6.1930e-04 - val_loss: 4.7297\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 4.9143e-04 - val_loss: 4.7449\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 3.7840e-04 - val_loss: 4.7633\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 3.2010e-04 - val_loss: 4.7863\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 4s 251ms/step - loss: 2.6109e-04 - val_loss: 4.7925\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 3.5861e-04 - val_loss: 4.8009\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 9.0963e-04 - val_loss: 4.8159\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 6.5800e-04 - val_loss: 4.7934\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 1.9340e-04 - val_loss: 4.8115\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 1.4726e-04 - val_loss: 4.8295\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 4s 250ms/step - loss: 1.1571e-04 - val_loss: 4.8392\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 9.6248e-05 - val_loss: 4.8605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1acbc5f1048>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('nmthien_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: president attends the th annual convocation of iit kanpur rashtrapati bhavan\n",
      "Actual Hindi Translation:  राष्ट्रपति जी ने भारतीय प्रौद्योगिकी संस्थानकानपुर के वें दीक्षांत समारोह में भाग लिया। राष्ट्रपति भवन \n",
      "Predicted Hindi Translation:  राष्ट्रपति जी ने भारतीय प्रौद्योगिकी संस्थानका\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: the extenuating factor may help reforming a person\n",
      "Actual Hindi Translation:  परिशमनकारी तत्व किसी व्यक्ति के सुधार में सहायक हो सकते हैं। \n",
      "Predicted Hindi Translation:  परिशमनकारी तत्व किसी व्यक्ति के सुधार में सहाय\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
